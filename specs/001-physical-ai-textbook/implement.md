# Physical AI & Humanoid Robotics Textbook - Implementation Guide

====================================================================
## 1. Overview & Goals
====================================================================

This project implements a professional robotics education platform featuring a comprehensive 19-module textbook, premium homepage, floating chatbot, and Gemini-powered RAG backend. The system is built using Docusaurus for the frontend, FastAPI for the backend, Qdrant for vector storage, and PostgreSQL for metadata management.

### Technical Goals:
- Create a complete MDX-based textbook with 19 modules following the spec.md structure
- Implement a professional homepage with gradient background and all required sections
- Build a floating chatbot with Gemini RAG integration
- Establish a robust backend RAG pipeline with proper ingestion and querying
- Maintain professional design standards with no futuristic/sci-fi elements

### High-level Architecture:
- **Frontend**: Docusaurus (React/TypeScript) with MDX support for textbook content
- **Backend**: FastAPI with Gemini integration for embeddings and chat
- **Vector DB**: Qdrant for storing textbook embeddings
- **Metadata DB**: PostgreSQL for module metadata and counters
- **CI/CD**: GitHub Actions for automated testing and deployment
- **Hosting**: Frontend on Vercel/Netlify, Backend on Railway/Render/VM

====================================================================
## 2. Repository Layout (Concrete File Tree)
====================================================================

```
/repo-root
  /frontend
    /docs                   # MDX modules (19 folders)
      /01-intro
        index.mdx
      /02-robotics-fundamentals
        index.mdx
      /03-ros2-foundations
        index.mdx
      /04-urdf-models
        index.mdx
      /05-kinematics
        index.mdx
      /06-robot-dynamics
        index.mdx
      /07-sensors-perception
        index.mdx
      /08-gazebo-simulation
        index.mdx
      /09-isaac-sim
        index.mdx
      /10-unity-robotics
        index.mdx
      /11-vslam
        index.mdx
      /12-navigation
        index.mdx
      /13-locomotion
        index.mdx
      /14-vla-robotics
        index.mdx
      /15-digital-twin
        index.mdx
      /16-jetson-robotics
        index.mdx
      /17-system-architecture
        index.mdx
      /18-capstone
        index.mdx
      /19-glossary
        index.mdx
    /src
      /components
        /Animations
          ScrollAnimations.js
        /Chatbot
          Chatbot.js
          ChatbotProvider.js
          RAGSystem.js
        /Homepage
          HeroSection.js
          ModuleGrid.js
          CounterAnimation.js
        /Layout
          ClientLayout.js
          ClientProvider.js
        /Theme
          Root.tsx
      /pages
        index.js
      /css
        custom.css
    static/
      /img
        logo.svg
        favicon.ico
    docusaurus.config.js
    sidebars.js
    tailwind.config.js
    postcss.config.js
    tsconfig.json
    package.json
    .gitignore
  /backend
    /app
      main.py
      /routers
        embed.py
        ingest.py
        query.py
        chat.py
        metadata.py
      /services
        gemini_service.py
        rag_pipeline.py
        embeddings.py
      /models
        chat_models.py
        module_models.py
      /database
        qdrant_service.py
        postgres_models.py
      /utils
        chunker.py
        context_builder.py
    Dockerfile
    requirements.txt
    alembic/
      alembic.ini
      env.py
      /versions
    .gitignore
  /ops
    docker-compose.yml
    k8s/
      deployment.yaml
      service.yaml
    ci/
      pipeline.yml
  /scripts
    ingest_all.sh
    setup_env.sh
  .env.example
  README.md
  .gitignore
```

====================================================================
## 3. Frontend Implementation Details
====================================================================

3.1 Docusaurus Setup
- Commands to initialize Docusaurus with TypeScript
  - `npx create-docusaurus@latest my-site classic --typescript`
- Where to place MDX module folders
- Sidebar auto-generation approach (script / manual sidebar.js)

Initialize Docusaurus with TypeScript support:

```bash
npx create-docusaurus@latest my-site classic --typescript
cd my-site
npm install @docusaurus/module-type-aliases @docusaurus/types
```

Place MDX module folders in `/frontend/docs/` following the 19-module structure from spec.md.

For sidebar auto-generation, create `/frontend/sidebars.js`:

```javascript
// sidebars.js
module.exports = {
  textbook: [
    {
      type: 'autogenerated',
      dirName: '.',
    },
  ],
};
```

3.2 Tailwind & Fonts
- Tailwind install commands and minimal `tailwind.config.js` example showing `fontFamily` tokens:
  - `Sora`, `Syncopate`, `Inter`, `Orbitron` entries
- Show snippet for `globals.css` with `@tailwind base; @tailwind components; @tailwind utilities;` and font-face import (or Google Fonts link)
- Provide sample Tailwind tokens for gradient and color palette:
  - `--bg-gradient: linear-gradient(to bottom right, #000000, #0A1A2F);`

Install Tailwind CSS:

```bash
cd frontend
npm install -D tailwindcss postcss autoprefixer
npx tailwindcss init -p
```

Configure `tailwind.config.js`:

```javascript
// tailwind.config.js
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./src/**/*.{js,jsx,ts,tsx}",
    "./docs/**/*.{md,mdx}",
    "./pages/**/*.{js,jsx,ts,tsx}",
    "./theme/**/*.{js,jsx,ts,tsx}",
  ],
  theme: {
    extend: {
      fontFamily: {
        'sora': ['Sora', 'sans-serif'],
        'syncopate': ['Syncopate', 'sans-serif'],
        'inter': ['Inter', 'sans-serif'],
        'orbitron': ['Orbitron', 'monospace'],
      },
      colors: {
        'dark-blue': '#0A1A2F',
      },
      backgroundImage: {
        'gradient-black-blue': 'linear-gradient(to bottom right, #000000, #0A1A2F)',
      }
    },
  },
  plugins: [],
}
```

Create `src/css/custom.css` with Tailwind directives and font imports:

```css
@tailwind base;
@tailwind components;
@tailwind utilities;

@import url('https://fonts.googleapis.com/css2?family=Sora:wght@300;400;500;600;700&family=Syncopate:wght@400;700&family=Inter:wght@300;400;500;600;700&family=Orbitron:wght@400;500;600;700&display=swap');

:root {
  --bg-gradient: linear-gradient(to bottom right, #000000, #0A1A2F);
}

body {
  font-family: 'Inter', sans-serif;
}

h1, h2, h3 {
  font-family: 'Sora', sans-serif;
}

h4, .section-label {
  font-family: 'Syncopate', sans-serif;
}

.numeric-accent {
  font-family: 'Orbitron', monospace;
}
```

3.3 Theme Overrides & Root Injection
- Explain `src/theme/Root.tsx` override to inject global providers (ThemeProvider, chatbot widget) and global layout
- Show example where the FloatingChatIcon is imported and added to the Root layout so it appears on all pages

Create `src/theme/Root.tsx` to inject global providers and the floating chatbot:

```tsx
// src/theme/Root.tsx
import React from 'react';
import { ChatbotProvider } from '../components/Chatbot/ChatbotProvider';
import FloatingChatIcon from '../components/Chatbot/Chatbot';

export default function Root({ children }) {
  return (
    <ChatbotProvider>
      {children}
      <FloatingChatIcon />
    </ChatbotProvider>
  );
}
```

3.4 Components & Sections (File list + behavior)
- List required components and brief responsibilities:
  - `HeroSection.tsx` (gradient usage)
  - `AboutSection.tsx`
  - `WhatWeDo.tsx`
  - `ModuleGrid.tsx` (fetches `/metadata/modules`)
  - `CounterAnimation.tsx` (fetches `/metadata/counters`)
  - `ServicesProvided.tsx`
  - `Testimonials.tsx`
  - `GetConnect.tsx`
  - `FloatingChatIcon.tsx` and `ChatWindow.tsx` (chat UI)
- For each component provide props, lifecycle behavior (e.g., ModuleGrid calls backend on mount), and Tailwind classes suggestions

Create the following components in `/frontend/src/components/`:

- `Homepage/HeroSection.js`: Uses the black→dark blue gradient background
- `Homepage/ModuleGrid.js`: Fetches `/metadata/modules` on component mount
- `Homepage/CounterAnimation.js`: Fetches `/metadata/counters` and animates values
- `Chatbot/Chatbot.js`: Floating chat icon and window component
- `Chatbot/ChatbotProvider.js`: Context provider for chat state
- `Layout/ClientLayout.js`: Client-side layout wrapper

3.5 Chatbot UI details
- Explain UI/UX: fixed bottom-right, accessible labels, aria attributes, mobile responsiveness behavior (minimized on smaller screens)
- Provide skeleton for streaming UI: message list, typing indicator, input box with submit, error states

The chatbot UI includes:
- Fixed bottom-right position with minimal styling
- Accessible labels and ARIA attributes
- Mobile-responsive (minimizes on smaller screens)
- Streaming message display with typing indicators
- Error handling states

3.6 Accessibility & Testing
- WCAG basics: contrast ratios, keyboard navigation for chatbot, aria-live for streamed messages
- Lighthouse testing steps

Ensure WCAG compliance:
- Maintain 4.5:1 contrast ratio for text
- Implement keyboard navigation for all interactive elements
- Use aria-live regions for streamed chat messages
- Run Lighthouse audits: `npm run build && npx serve -s build`

====================================================================
## 4. Backend Implementation Details
====================================================================

4.1 FastAPI Project Structure
- Provide `main.py` outline: include startup/shutdown events, router registration, dependency injection for DB clients
- Router design: `routers/embed.py`, `routers/ingest.py`, `routers/query.py`, `routers/chat.py`, `routers/metadata.py`

Create `backend/app/main.py`:

```python
from fastapi import FastAPI
from app.routers import embed, ingest, query, chat, metadata
from app.database.qdrant_service import get_qdrant_client
from app.database.postgres_models import engine, Base
import asyncio

app = FastAPI(
    title="Physical AI & Humanoid Robotics Textbook API",
    description="Backend API for textbook RAG system",
    version="1.0.0"
)

# Include routers
app.include_router(embed.router, prefix="/api/v1", tags=["embed"])
app.include_router(ingest.router, prefix="/api/v1", tags=["ingest"])
app.include_router(query.router, prefix="/api/v1", tags=["query"])
app.include_router(chat.router, prefix="/api/v1", tags=["chat"])
app.include_router(metadata.router, prefix="/api/v1", tags=["metadata"])

@app.on_event("startup")
async def startup_event():
    # Initialize database connections
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

@app.on_event("shutdown")
async def shutdown_event():
    # Cleanup connections
    pass
```

4.2 Gemini Integration
- Explain abstraction layer for LLM: `services/gemini_client.py` with functions `embed_text()`, `chat_stream()`, `chat_completion()`
- Mention rate limiting, batching embeddings, retry strategies, and error handling

Create `backend/app/services/gemini_service.py`:

```python
import google.generativeai as genai
from typing import List, Dict, Any
import os

class GeminiService:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.embedding_model = genai.GenerativeModel('embedding-001')

    async def embed_text(self, text: str) -> List[float]:
        response = await self.embedding_model.embed_content([text])
        return response.embedding[0]

    async def chat_completion(self, messages: List[Dict[str, str]]) -> str:
        # Convert messages to Gemini format and return response
        pass

    async def generate_response_stream(self, messages: List[Dict[str, str]], context: str = None):
        # Stream response from Gemini
        pass
```

4.3 Chunking & Ingestion Pipeline
- Provide `rag/chunker.py` responsibilities: chunk by headings, token limits, overlap strategy
- Provide `rag/ingest.py` flow:
  - Read MDX files
  - Strip MDX frontmatter & code fences where appropriate
  - Chunk content
  - Call Gemini embeddings
  - Push vectors to Qdrant with metadata (module, chapter, file path, heading)
  - Insert metadata rows to PostgreSQL

Create `backend/app/utils/chunker.py`:

```python
import re
from typing import List, Dict, Any

class TextChunker:
    def __init__(self, max_chunk_size: int = 1000, overlap: int = 100):
        self.max_chunk_size = max_chunk_size
        self.overlap = overlap

    def chunk_mdx_content(self, content: str, module_id: str, source_path: str) -> List[Dict[str, Any]]:
        # Remove MDX frontmatter and code blocks
        clean_content = self._remove_frontmatter(content)
        clean_content = self._remove_code_blocks(clean_content)

        # Split by headings to preserve context
        sections = self._split_by_headings(clean_content)

        chunks = []
        for section in sections:
            section_chunks = self._chunk_section(section, module_id, source_path)
            chunks.extend(section_chunks)

        return chunks

    def _remove_frontmatter(self, content: str) -> str:
        # Remove YAML frontmatter between --- delimiters
        pattern = r'^---\n.*?\n---\n'
        return re.sub(pattern, '', content, flags=re.DOTALL)

    def _remove_code_blocks(self, content: str) -> str:
        # Remove code blocks but preserve their descriptions
        pattern = r'```.*?\n.*?\n```'
        return re.sub(pattern, '', content, flags=re.DOTALL)

    def _split_by_headings(self, content: str) -> List[str]:
        # Split content by headings while preserving heading context
        headings = re.split(r'\n## ', content)
        sections = []
        for i, section in enumerate(headings):
            if i == 0:
                sections.append(section)
            else:
                sections.append(f"## {section}")
        return sections

    def _chunk_section(self, section: str, module_id: str, source_path: str) -> List[Dict[str, Any]]:
        # Break down large sections into smaller chunks
        chunks = []
        words = section.split()

        for i in range(0, len(words), self.max_chunk_size - self.overlap):
            chunk_words = words[i:i + self.max_chunk_size]
            chunk_text = ' '.join(chunk_words)

            chunks.append({
                'text': chunk_text,
                'module_id': module_id,
                'source_path': source_path,
                'chunk_index': len(chunks)
            })

        return chunks
```

4.4 Qdrant Schema & Indexing
- Suggest collection name `textbook_vectors`
- Suggest metadata fields: `module_id`, `module_title`, `chapter`, `section`, `source_path`, `token_count`, `created_at`
- Describe vector dimension placeholder (match Gemini embedding size) and indexing parameters

Collection name: `textbook_vectors`
Vector dimension: 768 (Gemini embedding size)
Metadata fields:
- `module_id`: String - identifier for the module
- `module_title`: String - title of the module
- `section`: String - section within the module
- `source_path`: String - file path of the source
- `token_count`: Integer - number of tokens in the chunk
- `created_at`: DateTime - timestamp of creation

4.5 PostgreSQL Schema
- Provide SQL table outlines:
  - `modules (id,name,slug,description,created_at,updated_at)`
  - `text_chunks (id,module_id,section,source_path,qdrant_id,tokens,created_at)`
  - `counters (name,value,updated_at)`
  - `chat_logs (id,session_id,user_message,bot_response,timestamp)`

```sql
-- Create modules table
CREATE TABLE modules (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    slug VARCHAR(255) UNIQUE NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create text_chunks table
CREATE TABLE text_chunks (
    id SERIAL PRIMARY KEY,
    module_id INTEGER REFERENCES modules(id) ON DELETE CASCADE,
    section VARCHAR(255),
    source_path VARCHAR(500),
    qdrant_id VARCHAR(100), -- ID in Qdrant vector DB
    tokens INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create counters table
CREATE TABLE counters (
    name VARCHAR(100) PRIMARY KEY,
    value INTEGER DEFAULT 0,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create chat_logs table
CREATE TABLE chat_logs (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(100),
    user_message TEXT,
    bot_response TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

4.6 API Behavior
- Describe each endpoint contract: inputs, outputs, error codes
  - `/embed` → accepts text, returns embedding vector
  - `/ingest` → starts ingestion job or ingests single file
  - `/query` → accepts vector/text query, returns top-K chunks with scores
  - `/chat` → accepts messages + optional context selector, streams back LLM responses
  - `/metadata/modules` → returns modules list and URLs
  - `/metadata/counters` → returns homepage counters (modules_count, chapters_count, exercises_count, etc.)

- `/api/v1/embed` → Accepts text in request body, returns embedding vector
- `/api/v1/ingest` → Triggers full textbook ingestion, returns job status
- `/api/v1/query` → Accepts query text, returns top-K relevant chunks with scores
- `/api/v1/chat` → Accepts message history, streams back LLM responses
- `/api/v1/metadata/modules` → Returns list of all textbook modules
- `/api/v1/metadata/counters` → Returns homepage counters (module count, etc.)

4.7 Streaming Chat Implementation
- Explain server-sent events (SSE) or WebSocket approach for streaming responses
- Provide guidance for incremental flushes to client and handling reconnects

Use Server-Sent Events (SSE) for streaming responses:

```python
from fastapi import Response
from typing import AsyncGenerator

async def generate_chat_stream(user_message: str, context: str) -> AsyncGenerator[str, None]:
    # Generate response incrementally and yield as SSE events
    yield f"data: {chunk}\n\n"
```

4.8 Security & Secrets
- Environment variables list:
  - `GEMINI_API_KEY`, `DATABASE_URL`, `QDRANT_URL`, `QDRANT_API_KEY`, `JWT_SECRET`, `SENTRY_DSN`
- Suggest secret management and limited-permission API keys
- CORS policy and rate limiting

Environment variables required:
- `GEMINI_API_KEY` - Google Gemini API key
- `DATABASE_URL` - PostgreSQL connection string
- `QDRANT_URL` - Qdrant connection URL
- `QDRANT_API_KEY` - Qdrant API key
- `JWT_SECRET` - Secret for JWT token generation
- `SENTRY_DSN` - Optional Sentry error tracking

====================================================================
## 5. DevOps, Containerization & CI/CD
====================================================================

5.1 Dockerfiles & docker-compose
- Provide example `Dockerfile` outlines for frontend & backend
- Provide `docker-compose.yml` to run postgres, qdrant, backend, frontend locally

Frontend Dockerfile (`frontend/Dockerfile`):
```dockerfile
FROM node:18-alpine

WORKDIR /app
COPY package*.json ./
RUN npm install

COPY . .
RUN npm run build

EXPOSE 3000
CMD ["npm", "run", "serve"]
```

Backend Dockerfile (`backend/Dockerfile`):
```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Docker Compose (`ops/docker-compose.yml`):
```yaml
version: '3.8'

services:
  frontend:
    build: ../frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://localhost:8000

  backend:
    build: ../backend
    ports:
      - "8000:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DATABASE_URL=${DATABASE_URL}
      - QDRANT_URL=${QDRANT_URL}
    depends_on:
      - postgres
      - qdrant

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: textbook_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  qdrant:
    image: qdrant/qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"

volumes:
  postgres_data:
  qdrant_data:
```

5.2 CI/CD Pipeline
- Provide example pipeline steps (GitHub Actions / GitLab CI / CircleCI):
  - lint (ESLint, flake8)
  - test (unit, integration)
  - build (frontend production build)
  - build (backend docker image)
  - deploy (push to registry & deploy to host)

Example GitHub Actions workflow (`.github/workflows/ci-cd.yml`):
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Lint frontend
      run: |
        cd frontend
        npm run lint

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install backend dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install pytest flake8

    - name: Lint backend
      run: |
        cd backend
        flake8 .

    - name: Run backend tests
      run: |
        cd backend
        pytest

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Login to DockerHub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build and push frontend
      uses: docker/build-push-action@v4
      with:
        context: ./frontend
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/textbook-frontend:latest

    - name: Build and push backend
      uses: docker/build-push-action@v4
      with:
        context: ./backend
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/textbook-backend:latest
```

5.3 Kubernetes / Optional
- High-level k8s manifests for backend deployment, qdrant statefulset, postgres statefulset
- Notes about horizontal autoscaling and health checks

5.4 Backups & Monitoring
- Database backups policy (daily snapshots for Postgres, backups for Qdrant)
- Monitoring stack suggestions: Prometheus + Grafana, Sentry for errors, Datadog optional
- Logging: structured logs (JSON), correlation IDs, retention policy

====================================================================
## 6. Testing Strategy
====================================================================

6.1 Unit Tests
- Frontend: component unit tests (Jest + React Testing Library)
- Backend: pytest for services and endpoints

6.2 Integration Tests
- Test ingestion pipeline
- Test /chat streaming with mocked Gemini responses

6.3 E2E Tests
- Cypress tests: homepage, module navigation, chatbot usage

6.4 Performance Testing
- Load test RAG endpoints with K6 / Locust
- Target latencies for /query and /chat

### 6.1 Unit Tests
- Frontend: Jest + React Testing Library for component testing
- Backend: pytest for service and utility functions

### 6.2 Integration Tests
- Test the ingestion pipeline end-to-end
- Test RAG query functionality with real embeddings
- Test metadata endpoints with database integration

### 6.3 E2E Tests
- Cypress tests for:
  - Homepage navigation
  - Module browsing
  - Chatbot functionality
  - Mobile responsiveness

### 6.4 Performance Testing
- Load test RAG endpoints using Locust or K6
- Target <200ms response time for queries
- Target <500ms response time for chat

====================================================================
## 7. Deployment & Runbook
====================================================================

7.1 Staging & Production
- Branching rules: main → production, develop → staging
- Staging deploy on PR merge to develop
- Production deploy on tag or protected merge

7.2 Runbook Items
- Restarting services
- Re-running ingestion
- Rotating Gemini API keys
- Restoring Postgres backups
- Scaling Qdrant

### 7.1 Staging & Production
- `develop` branch → Staging environment (auto-deploy)
- `main` branch → Production environment (manual approval)


### 7.2 Runbook Items

**Restart services:**
```bash
docker-compose down && docker-compose up -d
```

**Re-run ingestion:**
```bash
cd backend && python -m app.routers.ingest --full-reindex
```

**Rotate API keys:**
Update environment variables and restart services

**Restore Postgres backup:**
```bash
pg_restore -d textbook_db backup_file.dump
```

====================================================================
## 8. Observability & Maintenance
====================================================================

- Metrics to capture: request rates, latencies, embedding rates, ingestion rates, error rates
- Dashboards to build: traffic, chatbot usage, RAG hit-rate
- Maintenance tasks: reindex vectors, re-ingest content after large updates

### Metrics to capture:
- Request rates and latencies for all endpoints
- Embedding generation rates
- Ingestion pipeline status
- Error rates and types
- Chatbot usage statistics

### Dashboards to build:
- System health dashboard
- RAG performance metrics
- User engagement metrics
- Resource utilization

### Maintenance tasks:
- Weekly re-indexing of content
- Monthly database cleanup
- Quarterly dependency updates
- Annual embedding model updates

====================================================================
## 9. Security & Compliance
====================================================================

- Least privilege DB access
- HTTPS only
- Input validation for ingestion
- Rate limiting on /chat
- GDPR/retention policy for chat logs

### Security considerations:
- Implement rate limiting on all endpoints
- Validate all user inputs
- Use parameterized queries to prevent SQL injection
- Implement HTTPS-only connections
- Store chat logs with GDPR compliance
- Regular security scanning of dependencies

====================================================================
## 10. Migration & Upgrade Strategy
====================================================================

- Handling embedding model upgrades (re-embed plan)
- Qdrant schema migrations
- Alembic migrations for PostgreSQL
- Version control for textbook modules

### Upgrade Strategy:
- For embedding model upgrades: re-embed all content with new model
- Use Alembic for PostgreSQL schema migrations
- Maintain backward compatibility for API endpoints
- Version textbook modules separately from platform

====================================================================
## 11. Example Commands & Scripts
====================================================================

- `pnpm install` / `npm install` / `pip install -r requirements.txt`
- `yarn start`
- `uvicorn backend.app.main:app --reload`
- `./scripts/ingest_all.sh`
- `docker-compose up --build`
- Example curl: `/metadata/modules`, `/chat`

### Example Commands:
```bash
# Install dependencies
cd frontend && npm install
cd backend && pip install -r requirements.txt

# Start development servers
cd frontend && npm start
cd backend && uvicorn app.main:app --reload

# Run ingestion script
./scripts/ingest_all.sh

# Build and run with Docker
docker-compose up --build

# Test API endpoints
curl http://localhost:8000/api/v1/metadata/modules
curl http://localhost:8000/api/v1/metadata/counters
```

====================================================================
## 12. Rollout & Completion Checklist
====================================================================

- [ ] Repo structure ready
- [ ] Docusaurus builds successfully
- [ ] All 19 modules added
- [ ] Tailwind + fonts configured
- [ ] Gradient applied globally
- [ ] Backend endpoints running
- [ ] Ingestion pipeline working
- [ ] Module metadata & counters functional
- [ ] Floating chatbot working globally
- [ ] Chat streaming enabled
- [ ] CI pipeline passing
- [ ] Staging & production deployed
- [ ] Monitoring + backups configured
- [ ] Security review completed

====================================================================
## 13. Appendix: Useful Snippets & Templates
====================================================================

### Tailwind gradient + fonts tokens
```css
@layer base {
  :root {
    --gradient-start: #000000;
    --gradient-end: #0A1A2F;
    --bg-gradient: linear-gradient(to bottom right, #000000, #0A1A2F);
  }
}

body {
  font-family: 'Inter', sans-serif;
}

h1, h2, h3 {
  font-family: 'Sora', sans-serif;
}

h4, .section-label {
  font-family: 'Syncopate', sans-serif;
}

.numeric-accent {
  font-family: 'Orbitron', monospace;
}
```

### Root.tsx override example
```tsx
// src/theme/Root.tsx
import React from 'react';
import { ChatbotProvider } from '../components/Chatbot/ChatbotProvider';
import FloatingChatIcon from '../components/Chatbot/Chatbot';

export default function Root({ children }) {
  return (
    <ChatbotProvider>
      {children}
      <FloatingChatIcon />
    </ChatbotProvider>
  );
}
```

### docker-compose.yml snippets (qdrant + postgres)
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: textbook_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  qdrant:
    image: qdrant/qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"

volumes:
  postgres_data:
  qdrant_data:
```

### SQL templates (modules, chunks)
```sql
-- Create modules table
CREATE TABLE modules (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    slug VARCHAR(255) UNIQUE NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create text_chunks table
CREATE TABLE text_chunks (
    id SERIAL PRIMARY KEY,
    module_id INTEGER REFERENCES modules(id) ON DELETE CASCADE,
    section VARCHAR(255),
    source_path VARCHAR(500),
    qdrant_id VARCHAR(100), -- ID in Qdrant vector DB
    tokens INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create counters table
CREATE TABLE counters (
    name VARCHAR(100) PRIMARY KEY,
    value INTEGER DEFAULT 0,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create chat_logs table
CREATE TABLE chat_logs (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(100),
    user_message TEXT,
    bot_response TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### curl examples
```bash
# Get all modules
curl -X GET http://localhost:8000/api/v1/metadata/modules

# Get counters for homepage
curl -X GET http://localhost:8000/api/v1/metadata/counters

# Query RAG system
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is forward kinematics?", "top_k": 5}'

# Chat with streaming
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Explain robot dynamics"}]}'
```
