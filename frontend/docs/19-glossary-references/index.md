---
sidebar_position: 1
title: "Glossary & References"
---

# Glossary & References

## Learning Objectives

By the end of this module, you should be able to:

- Define key terms commonly used in Physical AI and Humanoid Robotics
- Understand the relationships between different concepts in the field
- Access and utilize academic and technical references in robotics research
- Apply terminology correctly when discussing robotics concepts
- Use the glossary as a reference tool for future robotics work

## Overview

This module serves as a comprehensive reference for the terminology, concepts, and academic foundations that underpin the entire Physical AI and Humanoid Robotics textbook. It provides clear definitions of key terms, explains relationships between concepts, and offers a curated list of references for further study and research.

The glossary component helps standardize language within the field and provides a common foundation for communication about robotics concepts. The references section offers pathways to deeper understanding of foundational and advanced topics in robotics research and development.

## Glossary

### A

**Actuator**: A mechanical device that converts energy (typically electrical) into motion. In robotics, actuators are used to create movement in joints and other parts of the robot.

**Admittance Control**: A control strategy that relates forces applied to a robot to the resulting motion, making the robot behave like a mass-spring-damper system.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

**Autonomous System**: A system that operates independently without human intervention, making decisions based on sensor input and pre-programmed or learned behaviors.

### B

**Behavior Tree**: A hierarchical structure used in robotics and AI to represent and control the behavior of autonomous agents.

**Bipedal Locomotion**: The act of walking on two legs, which is a key challenge in humanoid robotics due to the need for dynamic balance.

**Bounding Box**: A rectangular frame that bounds an object in an image, used in computer vision for object detection and localization.

**Brushless Motor**: An electric motor that uses an electronic controller to switch DC voltages to the motor windings, commonly used in robotics for precise control.

### C

**Capture Point**: A point on the ground where a robot should step to stop its current motion and maintain balance, crucial in humanoid robotics.

**Central Pattern Generator (CPG)**: A neural network that produces rhythmic outputs without rhythmic inputs, used to generate walking patterns.

**CLIP (Contrastive Language-Image Pre-training)**: A neural network that learns visual concepts from natural language supervision.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world using digital images and deep learning models.

**Control Theory**: An interdisciplinary branch of engineering and mathematics that deals with the behavior of dynamical systems with inputs and how their behavior is modified by feedback.

**Coordinate Frame**: A coordinate system used to define the position and orientation of objects in space, fundamental in robotics for navigation and manipulation.

**Coulomb Friction**: The force that opposes the sliding motion between two surfaces in contact, important in robotic grasping and manipulation.

### D

**Deep Learning**: A subset of machine learning that uses artificial neural networks with many layers to model and understand complex patterns in data.

**Degree of Freedom (DOF)**: The number of independent parameters that define the configuration or state of a mechanical system.

**Denavit-Hartenberg (DH) Parameters**: A method for defining coordinate frames on robot linkages and describing the kinematic structure of robots.

**Differential Drive**: A common configuration for wheeled mobile robots using two independently driven wheels on a common axis.

**Dynamic Window Approach (DWA)**: A local path planning algorithm for mobile robots that samples velocities in a robot's action space to find a path that satisfies constraints while maximizing an objective function.

### E

**Embodied Intelligence**: Intelligence that emerges from the interaction between an intelligent system and its physical environment.

**Encoder**: A sensor that measures the position or motion of a rotating shaft, commonly used in robotics for joint position feedback.

**End-Effector**: The tool or device attached to the end of a robot arm that interacts with the environment.

**Episodic Memory**: A component of long-term memory that records personal experiences and specific events in time and space.

**Evolutionary Robotics**: A methodology for the automatic creation of adaptive and robust robotic systems through evolutionary algorithms.

### F

**Forward Kinematics**: The use of kinematic equations to compute the position of the robot's end-effector based on the joint angles.

**Fuzzy Logic**: A mathematical approach to handle uncertainty by allowing partial membership in sets, used in robotics for control systems.

### G

**Gazebo**: A 3D simulation environment for robotics that provides accurate physics simulation and realistic sensor models.

**Generalization**: The ability of a machine learning model to perform well on data not seen during training.

**Gripper**: A device at the end of a robot arm designed to grasp and manipulate objects.

**Ground Truth**: The real state of the world, often used as a reference to evaluate the accuracy of estimation algorithms.

**Gyroscopic Effect**: The tendency of a rotating body to maintain its axis of rotation, important in balancing robots.

### H

**Hardware-in-the-Loop (HIL)**: A testing method that connects real hardware to a simulation environment for more realistic testing.

**Heuristic**: A practical approach to problem-solving that is not guaranteed to be optimal but is sufficient for achieving immediate goals.

**Humanoid Robot**: A robot with a human-like form and movement capabilities, designed to operate in human environments.

### I

**Impedance Control**: A control strategy that regulates the mechanical impedance (resistance to motion) of a robot.

**Inertial Measurement Unit (IMU)**: A device that measures and reports on a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics**: The use of kinematic equations to determine the joint parameters that achieve a desired position of the robot's end-effector.

**Isaac Sim**: NVIDIA's robotics simulation platform built on the Omniverse platform with high-fidelity physics and rendering.

**Iterative Learning Control (ILC)**: A control method that improves tracking performance by learning from repeated tasks.

### J

**Joint Space**: The space defined by the robot's joint angles, as opposed to Cartesian space defined by position and orientation.

**Jacobian Matrix**: In robotics, a matrix that relates the joint velocities of a robot to the Cartesian velocity of the end-effector.

### K

**Kalman Filter**: An algorithm that uses a series of measurements observed over time to estimate unknown variables, often used in robotics for sensor fusion.

**Kinematics**: The branch of mechanics that describes the motion of objects without considering the forces that cause the motion.

### L

**LiDAR (Light Detection and Ranging)**: A sensing method that measures distances by illuminating a target with laser light and measuring the reflection.

**Local Minima**: Points in an optimization space where the function value is smaller than at nearby points but not necessarily the smallest possible value.

**Locomotion**: The ability to move from one place to another, a fundamental capability in mobile robotics.

**Loop Closure**: In SLAM, the identification and correction for when a robot returns to a previously visited location to correct accumulated errors.

### M

**Machine Learning**: A subset of AI that enables systems to learn and improve from experience without being explicitly programmed.

**Manipulator**: A robot arm designed to manipulate objects in the environment.

**Model Predictive Control (MPC)**: An advanced control method that uses a model of the system to predict future behavior and optimize control actions.

**Motion Planning**: The computational problem of finding a sequence of valid configurations that moves the robot from a start to goal state.

### N

**Navigation**: The capability of a robot to move through an environment from a starting position to a goal position.

**Neural Network**: A computing system inspired by the human brain, used in AI to recognize patterns and solve complex problems.

**Non-holonomic Constraint**: A constraint that cannot be expressed as a function of position coordinates alone, common in wheeled robots.

### O

**Occupancy Grid**: A probabilistic representation of space that divides the environment into discrete cells and assigns a probability of occupancy to each cell.

**Odometry**: The use of data from motion sensors to estimate change in position over time, frequently used in robotics for localization.

**OpenCV**: An open-source computer vision library used for various image processing and computer vision tasks.

**Operational Space**: The space in which task-specific variables are defined, typically Cartesian position and orientation.

### P

**Path Planning**: The computational process of finding a feasible path from a start to a goal while avoiding obstacles.

**Perception**: The process by which robots interpret sensor data to understand their environment.

**PID Controller**: A control loop mechanism employing proportional, integral, and derivative terms to minimize error between desired and actual values.

**Point Cloud**: A collection of data points in 3D space, typically obtained from 3D scanners or LiDAR sensors.

### Q

**Quaternion**: A mathematical entity used to represent rotations in 3D space, commonly used in robotics for orientation representation.

**Q-Learning**: A model-free reinforcement learning algorithm that learns the value of actions in particular states.

**Q-learning**: A reinforcement learning algorithm used to learn optimal action policies in discrete state-action spaces.

### R

**RANSAC (Random Sample Consensus)**: An iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers.

**Real-time**: Systems that must respond to inputs within strict timing constraints.

**Reactive System**: A system that continuously responds to changes in its environment rather than executing a predetermined sequence of actions.

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System (ROS)**: Flexible framework for writing robot software, providing services for hardware abstraction, device drivers, and message passing.

**ROS 2**: The second generation of the Robot Operating System with improved architecture for real-world applications.

**Rigid Body**: An object that maintains its shape regardless of forces applied to it, fundamental to robot kinematics and dynamics.

### S

**Sensor Fusion**: The process of combining data from multiple sensors to provide a more accurate and comprehensive representation of the environment.

**Simultaneous Localization and Mapping (SLAM)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location.

**Singularity**: A configuration in which the robot loses one or more degrees of freedom due to alignment of joint axes.

**State Estimation**: The process of estimating the internal state of a system from measurements and a model of the system.

**Stereovision**: The process of extracting 3D information from digital images taken by two cameras positioned at slightly different angles.

**Support Polygon**: The area defined by the points of contact between a robot and its supporting surface, used to determine stability.

### T

**Trajectory**: A path with an associated time parameterization that specifies how a robot should move through space over time.

**Transform**: A mathematical operation that describes the position and orientation of one coordinate frame relative to another.

**Twist**: A 6D vector representing the linear and angular velocity of a rigid body.

### V

**Variance**: A measure of how far a set of numbers is spread out from their average value, important in sensor accuracy and control systems.

**Velocity Obstacle**: A region in velocity space that represents all velocities that would cause a collision between two robots within a certain time.

**Vision-Language-Action (VLA) Robotics**: A paradigm that connects natural language commands to visual perception and physical robot actions.

**Visual SLAM**: SLAM that uses visual sensors such as cameras to build maps and localize the robot.

### W

**Whole-Body Control**: A control approach for humanoid robots that coordinates all degrees of freedom simultaneously to achieve multiple tasks.

**Wheel Odometry**: The use of sensors to count wheel rotations to estimate distance traveled, commonly used in mobile robots.

**Workspace**: The volume of space that a robot's end-effector can reach.

### Z

**Zero Moment Point (ZMP)**: A point where the sum of moments of the contact forces equals zero, used in humanoid robotics for balance control.

**ZMP (Zero Moment Point)**: A criterion for dynamic balance in walking robots where the ground reaction force produces zero moment about the point.

## References

### Foundational Robotics Textbooks

1. Siciliano, B., & Khatib, O. (Eds.). (2016). *Springer Handbook of Robotics* (2nd ed.). Springer. ISBN: 978-3-319-32550-7.
   - Comprehensive reference covering all aspects of robotics research and development.

2. Spong, M. W., Hutchinson, S., & Vidyasagar, M. (2006). *Robot Modeling and Control*. Wiley. ISBN: 0-471-64990-2.
   - Classic textbook on robot modeling, control, and dynamics.

3. Craig, J. J. (2005). *Introduction to Robotics: Mechanics and Control* (3rd ed.). Prentice Hall. ISBN: 0-201-54361-3.
   - Widely used textbook for learning robot kinematics, dynamics, and control.

4. Lynch, K. M., & Park, F. C. (2017). *Modern Robotics: Mechanics, Planning, and Control*. Cambridge University Press. ISBN: 978-1107156302.
   - Modern approach to robotics with emphasis on geometric mechanics.

### Humanoid Robotics Specialized Literature

5. Kajita, S. (2019). *Introduction to Humanoid Robotics*. Springer. ISBN: 978-3-642-41146-9.
   - In-depth treatment of humanoid-specific challenges and solutions.

6. Asfour, T. (2020). "Humanoid Robotics: A Reference" (2nd ed.). Springer. ISBN: 978-3-319-95269-8.
   - Comprehensive reference on humanoid robotics research and development.

7. Nakanishi, J., Cory, R., Mistry, M., Peters, J., & Schaal, S. (2008). "Operational space control: A theoretical and empirical comparison." *The International Journal of Robotics Research*, 27(6), 737-757.
   - Foundational paper on operational space control for humanoid robots.

8. Koolen, T., De Boer, T., Rebula, J., Goswami, A., & Pratt, J. (2012). "Capturability-based pattern generation for walking with variable height ZMP". *IEEE International Conference on Robotics and Automation*, 2012.
   - Important research on walking control for humanoid robots.

### Artificial Intelligence and Machine Learning in Robotics

9. Russell, S., & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson. ISBN: 978-0134610993.
   - Comprehensive textbook on AI, including robotics applications.

10. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. ISBN: 978-0262035613.
    - Authoritative text on deep learning techniques applicable to robotics.

11. SÃ¼nderhauf, N., et al. (2022). "A manifesto for embodied intelligence". *Frontiers in Neurorobotics*, 16, 1041459.
    - Discusses the importance of embodiment in AI systems.

12. Chen, K., et al. (2023). "OpenVLA: An Open-Source Vision-Language-Action Model". arXiv preprint arXiv:2310.08820.
    - Recent work on vision-language-action robotics models.

### Simulation and Development Tools

13. Quigley, M., et al. (2009). "ROS: an open-source Robot Operating System". *ICRA Workshop on Open Source Software*, 3(3.2), 5.
    - Original paper describing the Robot Operating System framework.

14. NVIDIA. (2023). "Isaac Sim: NVIDIA Omniverse-based robotics simulation application".
    - Documentation for NVIDIA's advanced robotics simulation platform.

15. Koene, A., et al. (2014). "Gazebo: A 3D multi-robot simulator". *IEEE Robotics & Automation Magazine*, 21(3), 110-111.
    - Paper describing the Gazebo simulation environment.

### Research Papers and Academic Articles

16. Fox, D., Burgard, W., & Thrun, S. (1997). "The dynamic window approach to collision avoidance". *IEEE Robotics & Automation Magazine*, 4(1), 23-33.
    - Foundational paper on local navigation and obstacle avoidance.

17. Durrant-Whyte, H., & Bailey, T. (2006). "Simultaneous localization and mapping: part I". *IEEE Robotics & Automation Magazine*, 13(2), 99-110.
    - Part of seminal series on SLAM algorithms.

18. Khatib, O. (1986). "Real-time obstacle avoidance for manipulators and mobile robots". *The International Journal of Robotics Research*, 5(1), 90-98.
    - Original paper on artificial potential fields for obstacle avoidance.

19. Thrun, S., Burgard, W., & Fox, D. (2005). *Probabilistic Robotics*. MIT Press. ISBN: 0-262-20162-3.
    - Comprehensive treatment of probabilistic techniques in robotics.

20. Pfeifer, R., Lungarella, M., & Iida, F. (2007). "Self-organization, embodiment, and biologically inspired robotics". *Science*, 318(5853), 1088-1093.
    - Important paper on the role of embodiment in robotics.

### Vision and Perception

21. Szeliski, R. (2022). *Computer Vision: Algorithms and Applications* (2nd ed.). Springer. ISBN: 978-3-030-91498-6.
    - Comprehensive treatment of computer vision algorithms relevant to robotics.

22. Fischler, M. A., & Bolles, R. C. (1981). "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography". *Communications of the ACM*, 24(6), 381-395.
    - Original paper on RANSAC algorithm used in computer vision and robotics.

### Control Systems

23. Ogata, K. (2010). *Modern Control Engineering* (5th ed.). Prentice Hall. ISBN: 978-0136156734.
    - Standard textbook on control engineering principles.

24. Slotine, J. J. E., & Li, W. (1991). *Applied Nonlinear Control*. Prentice Hall. ISBN: 0-13-040890-1.
    - Advanced treatment of nonlinear control systems important in robotics.

### Safety and Ethics in Robotics

25. Lin, P., Abney, K., & Bekey, G. A. (Eds.). (2011). *Robot Ethics: The Ethical and Social Implications of Robotics*. MIT Press. ISBN: 978-0262017171.
    - Important work on ethical considerations in robotics.

26. Murphy, R., & Woods, D. D. (2009). "Beyond Asimov: An evidence-based approach to ethical considerations in robotics". *IEEE Intelligent Systems*, 24(4), 18-20.
    - Modern approach to robotics ethics beyond Asimov's laws.

## Appendix

### Mathematical Foundations

This section provides mathematical concepts used throughout the textbook:

**Linear Algebra**: Vectors, matrices, transformations, eigenvalues
**Calculus**: Derivatives, integrals, differential equations
**Probability Theory**: Random variables, probability distributions, Bayes' rule
**Statistics**: Estimation, hypothesis testing, regression

### Software Tools and Frameworks

**ROS/ROS2**: Robot Operating System
**Gazebo**: Physics-based simulation environment
**Isaac Sim**: NVIDIA's robotics simulation
**OpenCV**: Computer vision library
**TensorFlow/PyTorch**: Machine learning frameworks
**MoveIt**: Motion planning framework

## Summary

This glossary and references module provides a comprehensive reference for the terminology, concepts, and academic foundations of Physical AI and Humanoid Robotics. It serves as a resource for understanding key terms, accessing foundational literature, and continuing study in the field.

The glossary standardizes language within the field, providing clear definitions of technical terms. The references section offers pathways to deeper understanding through foundational textbooks, specialized literature, and current research in robotics. Together, these resources support continued learning and research in Physical AI and Humanoid Robotics.

As the field continues to evolve, this reference section will remain valuable for understanding both established concepts and emerging developments in humanoid robotics and embodied AI.