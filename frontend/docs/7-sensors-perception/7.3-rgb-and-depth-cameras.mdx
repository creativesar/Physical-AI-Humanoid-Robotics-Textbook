---
title: "7.3 RGB & Depth Cameras"
sidebar_label: "7.3 RGB & Depth Cameras"
---

import Mermaid from '@theme/Mermaid';

## Learning Outcomes

After completing this section, you will be able to:
- Understand the difference between RGB and depth cameras.
- Describe how depth cameras work (e.g., structured light, time-of-flight).
- Use camera data (images and point clouds) in ROS 2.
- Understand the concept of camera calibration.
- Use RGB and depth data for perception tasks like object detection and SLAM.

## 1. RGB Cameras

An RGB camera is a standard camera that captures color images. In robotics, RGB cameras are the "eyes" of the robot, providing rich visual information about the environment.

## 2. Depth Cameras

A depth camera, also known as an RGB-D camera, provides a depth map in addition to a color image. A depth map is an image where each pixel's value represents the distance from the camera to the object at that pixel.

There are several technologies for depth sensing:
- **Structured Light:** Projects a known pattern of light onto the scene and analyzes the deformation of the pattern to calculate depth.
- **Time-of-Flight (ToF):** Measures the time it takes for a light signal to travel from the camera to the object and back.
- **Stereo Vision:** Uses two cameras to infer depth by triangulation, similar to human vision.

... more content to be added here ...

## 3. Camera Data in ROS 2

ROS 2 provides standard message types for camera data: `sensor_msgs/Image` for 2D images and `sensor_msgs/PointCloud2` for depth data represented as a point cloud.

... more content to be added here ...

## 4. Camera Calibration

Camera calibration is the process of determining the intrinsic and extrinsic parameters of a camera. These parameters are essential for accurately relating the pixels in an image to real-world coordinates.

... more content to be added here ...

## 5. Using Camera Data for Perception

RGB and depth data are used in a wide variety of perception tasks, including:
- **Object Detection and Recognition:** Identifying and classifying objects in the scene.
- **Visual SLAM:** Using camera data to build a map of the environment and track the robot's position.
- **Scene Understanding:** Creating a semantic understanding of the environment.

... more content to be added here ...

## 6. Exercises

... exercises to be added here ...

## 7. Review Questions

... review questions to be added here ...
